{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import pdb\n",
    "\n",
    "torch.set_printoptions(linewidth = 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root = './data/FashionMNIST'\n",
    "    ,train = True\n",
    "    ,download = True\n",
    "    ,transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self,t):\n",
    "        #(1) input layer\n",
    "        t = t\n",
    "        \n",
    "        #(2) hidden conv layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        #(3) hidden conv layer\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        #(4) hidden linear layer\n",
    "        t = t.reshape(-1,12 * 4 * 4)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        #(5) hidden linear layer\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        #(6) output layer\n",
    "        t = self.out(t)\n",
    "        #t = F.softmax(t, dim=1)\n",
    "        \n",
    "        return t\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     train_set,\n",
    "#     batch_size=100\n",
    "# )\n",
    "# optimizer = optim.Adam(network.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds,labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_list = [100,1000,10000]\n",
    "lr_list = [.01,.001,.0001,.00001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 total_correct: 47585 loss: 33033.57497751713\n",
      "epoch: 1 total_correct: 51485 loss: 23053.107208013535\n",
      "epoch: 2 total_correct: 52071 loss: 21369.594030082226\n",
      "epoch: 3 total_correct: 52386 loss: 20374.2847725749\n",
      "epoch: 4 total_correct: 52562 loss: 19908.495746552944\n",
      "epoch: 0 total_correct: 42015 loss: 46570.40399312973\n",
      "epoch: 1 total_correct: 48276 loss: 30957.88463652134\n",
      "epoch: 2 total_correct: 50276 loss: 26423.177137970924\n",
      "epoch: 3 total_correct: 51535 loss: 23399.070486426353\n",
      "epoch: 4 total_correct: 52146 loss: 21560.758033394814\n",
      "epoch: 0 total_correct: 32649 loss: 82395.9949016571\n",
      "epoch: 1 total_correct: 42713 loss: 46788.60059380531\n",
      "epoch: 2 total_correct: 44248 loss: 41884.788912534714\n",
      "epoch: 3 total_correct: 45226 loss: 39024.42030310631\n",
      "epoch: 4 total_correct: 45810 loss: 37152.90271937847\n",
      "epoch: 0 total_correct: 11309 loss: 136967.87161827087\n",
      "epoch: 1 total_correct: 23829 loss: 126858.8387966156\n",
      "epoch: 2 total_correct: 30253 loss: 101814.82248306274\n",
      "epoch: 3 total_correct: 34424 loss: 81641.00608825684\n",
      "epoch: 4 total_correct: 36643 loss: 71690.40297269821\n",
      "epoch: 0 total_correct: 35288 loss: 64237.24114894867\n",
      "epoch: 1 total_correct: 46696 loss: 34314.69199061394\n",
      "epoch: 2 total_correct: 49763 loss: 27930.60576915741\n",
      "epoch: 3 total_correct: 51239 loss: 24022.86183834076\n",
      "epoch: 4 total_correct: 52120 loss: 21658.364951610565\n",
      "epoch: 0 total_correct: 26122 loss: 99425.65304040909\n",
      "epoch: 1 total_correct: 42747 loss: 46479.94267940521\n",
      "epoch: 2 total_correct: 44936 loss: 39903.24026346207\n",
      "epoch: 3 total_correct: 45877 loss: 36879.0265917778\n",
      "epoch: 4 total_correct: 46646 loss: 34729.29006814957\n",
      "epoch: 0 total_correct: 11506 loss: 137449.8426914215\n",
      "epoch: 1 total_correct: 18953 loss: 130376.48487091064\n",
      "epoch: 2 total_correct: 26226 loss: 103574.49293136597\n",
      "epoch: 3 total_correct: 36779 loss: 72863.51823806763\n",
      "epoch: 4 total_correct: 39664 loss: 58857.42223262787\n",
      "epoch: 0 total_correct: 6002 loss: 138336.08508110046\n",
      "epoch: 1 total_correct: 6004 loss: 138157.5312614441\n",
      "epoch: 2 total_correct: 6010 loss: 137948.4360218048\n",
      "epoch: 3 total_correct: 6065 loss: 137689.36681747437\n",
      "epoch: 4 total_correct: 6216 loss: 137356.79841041565\n",
      "epoch: 0 total_correct: 14251 loss: 120525.05493164062\n",
      "epoch: 1 total_correct: 24358 loss: 84898.45275878906\n",
      "epoch: 2 total_correct: 33322 loss: 65712.64386177063\n",
      "epoch: 3 total_correct: 38647 loss: 55337.27049827576\n",
      "epoch: 4 total_correct: 41477 loss: 49229.586124420166\n",
      "epoch: 0 total_correct: 9019 loss: 137610.70013046265\n",
      "epoch: 1 total_correct: 20620 loss: 134601.15432739258\n",
      "epoch: 2 total_correct: 25487 loss: 126336.06195449829\n",
      "epoch: 3 total_correct: 29615 loss: 108261.34443283081\n",
      "epoch: 4 total_correct: 33009 loss: 85193.86649131775\n",
      "epoch: 0 total_correct: 6710 loss: 138279.9768447876\n",
      "epoch: 1 total_correct: 8500 loss: 138191.48778915405\n",
      "epoch: 2 total_correct: 9865 loss: 138103.51371765137\n",
      "epoch: 3 total_correct: 10646 loss: 138003.08465957642\n",
      "epoch: 4 total_correct: 11087 loss: 137884.84573364258\n",
      "epoch: 0 total_correct: 6000 loss: 138503.75652313232\n",
      "epoch: 1 total_correct: 6000 loss: 138481.18782043457\n",
      "epoch: 2 total_correct: 6000 loss: 138458.24718475342\n",
      "epoch: 3 total_correct: 6000 loss: 138435.2469444275\n",
      "epoch: 4 total_correct: 6000 loss: 138412.0750427246\n"
     ]
    }
   ],
   "source": [
    "for batch_size in batch_size_list:\n",
    "    for lr in lr_list:\n",
    "        network = Network()\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_set, batch_size=batch_size\n",
    "        )\n",
    "        optimizer = optim.Adam(network.parameters(), lr=lr)\n",
    "        \n",
    "        images,labels = next(iter(train_loader))\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "        comment=f' batch_size={batch_size} lr={lr}'\n",
    "        tb = SummaryWriter(comment=comment)\n",
    "        tb.add_image('images', grid)\n",
    "        tb.add_graph(network, images)\n",
    "\n",
    "        for epoch in range(5):\n",
    "\n",
    "            total_loss = 0\n",
    "            total_correct = 0\n",
    "\n",
    "            for batch in train_loader:\n",
    "                images,labels = batch #get batch\n",
    "\n",
    "                preds = network(images) #pass batch\n",
    "                loss = F.cross_entropy(preds,labels) # calculate loss\n",
    "\n",
    "                optimizer.zero_grad() #zero gradients\n",
    "                loss.backward() # calculate gradients\n",
    "                optimizer.step()# Update weights\n",
    "\n",
    "                total_loss += loss.item() * batch_size\n",
    "                total_correct += get_num_correct(preds,labels)\n",
    "\n",
    "            tb.add_scalar('Loss', total_loss, epoch)\n",
    "            tb.add_scalar('Number Correct', total_correct, epoch)\n",
    "            tb.add_scalar('Accuracy', total_correct / len(train_set), epoch)\n",
    "            \n",
    "            for name, param in network.named_parameters():\n",
    "                tb.add_histogram(name, param, epoch)\n",
    "                tb.add_histogram(f'{name}.grad',param.grad,epoch)\n",
    "                \n",
    "            for name, weight in network.named_parameters():\n",
    "                tb.add_histogram(name, weight, epoch)\n",
    "                tb.add_histogram(f'{name}.grad',weight.grad,epoch)\n",
    "            \n",
    "            print('epoch:',epoch,\n",
    "                  'total_correct:', total_correct,\n",
    "                  'loss:', total_loss)\n",
    "        tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
